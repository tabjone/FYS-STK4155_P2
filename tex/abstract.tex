
\begin{abstract}
    %% TODO: IDK how good this sentence fits here now?
    In this project we did implement our own Feed Forward Neural Network (FFNN)
    with numerous optimization methods.    
    

    %%%% FEEL FREE TO REMOVE THIS AND RE-WRITE
    %GD METHODS
    We started by fitting a second order polynomial with the gradient decent
    methods of plain GD and stochastic with the AdaGrad and ADAM and RMSProp
    optimizers. We found that the stochastic methods in general converged
    faster (less iterations to reach low MSE) with larger minibatches. 

    Adding momentum was beneficial for all the gradient descent methods, except when 
    utilizing the ADAM optimizer. We discovered that the ADAM optimizer did a lot worse 
    than the other optimzers and than without any optimizer. AdaGrad and RMSprop performed 
    similarly and these optimizer excelled ecspecially when reducing the minibatch sizes. 
    
    AdaGrad was the most suitable optimizer for the polynomial fitting problem and produced
    a perfect fit to the target polynomial on eyesight. 

    %%NN
    When moving over to polynomial fitting with a Neural Network (NN) we found that a
    dense neural network with one hidden layer of 5 neurons produced the best results. 
    We analyzed the results using activation function Sigmoid, ReLU and leaky ReLU. Each activation
    function had its advantages and disadvantages with Sigmoid obtaining the best MSE score, but being
    most probable to get stuck on poor MSE scores, while the opposite was true for leaky ReLU, and 
    was in the midle with regards to both properties. 

    The resulting fit after 2000 iterations using Sigmoid was pretty similar to the target, allthough we could
    clearly see some deviations. 


    % Classification 
    In the last part we did a classification analysis on the Wisconsin Breast
    Cancer data. We experimented with different hyperparameter combinations.
    In our last run we tried to find the overall best parameter combination. 
    This resulted in an accuracy score of 0.9825 on our test data. According to
    the literature the result is better than what is to be expected for the
    Wisconsin Breast Cancer data. The reason is that we did not include any re
    sampling methods when we trained our model.

    We did find an error in the calculation of our L2 regularization parameter,
    $\lambda$. $\lambda $ was multiplied with the gradient of the weights
    instead of the weights from the previous iteration, effectively acting as
    an increased learning rate. Our analysis of the L2-regularization parameter
    is therefore invalid and should not be cited.  

\end{abstract}

\begin{comment}
    The abstract gives the reader a quick overview of what has been done and the most important results.

\end{comment}

